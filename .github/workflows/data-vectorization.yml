name: Data Vectorization and Artifact Deployment (RAG Pipeline)

on:
  # D√©clenchement manuel pour la production ou le test du pipeline
  workflow_dispatch:
  # D√©clenchement automatique lors de la mise √† jour des scripts ou d√©pendances RAG
  push:
    branches:
      - main
    paths:
      - 'src/data/**.py'
      - 'requirements.txt'

env:
  # Configuration des ressources cr√©√©es par le groupe 1
  AWS_REGION: ${{ secrets.AWS_REGION }}
  S3_BUCKET_NAME: "g1-data"
  # Chemin de destination (Dossier) pour l'artefact index vectoriel
  S3_ARTIFACT_KEY: "artifacts/vector_index/faiss_index" 
  PYTHON_VERSION: "3.10"
  
jobs:
  vectorize_and_upload:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      # --- Configuration de l'environnement Python ---
      - name: Set up Python Environment
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          # Installation des librairies RAG et AWS (boto3, awscli)
          pip install -r requirements.txt
          
      # --- Configuration des identifiants AWS Temporaires ---
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }} 
          aws-region: ${{ env.AWS_REGION }}

      # --- Ex√©cution du Data Pipeline (Vectorisation) ---
      - name: Execute Vectorization Pipeline
        run: |
          echo "Starting RAG data vectorization pipeline..."
          # Ce script g√©n√®re le dossier 'models/faiss_index' (sans .bin)
          python src/data/data_pipeline.py
          
          # V√©rification (Debug) : Affiche le contenu g√©n√©r√© pour √™tre s√ªr
          echo "üìÇ Contenu g√©n√©r√© dans models/ :"
          ls -R models/
          echo "Pipeline execution complete."

      # --- D√©ploiement de l'Artefact Index vers S3 ---
      - name: Deploy Vector Index Artifact to S3
        run: |
          echo "Uploading generated artifact to S3: s3://${{ env.S3_BUCKET_NAME }}/${{ env.S3_ARTIFACT_KEY }}"
          
          # CORRECTION CRUCIALE ICI :
          # 1. On cible le dossier 'models/faiss_index' (pas le fichier .bin)
          # 2. On ajoute '--recursive' pour copier tout le contenu du dossier
          aws s3 cp models/faiss_index s3://${{ env.S3_BUCKET_NAME }}/${{ env.S3_ARTIFACT_KEY }} --recursive
          
          echo "Artifact successfully deployed."
